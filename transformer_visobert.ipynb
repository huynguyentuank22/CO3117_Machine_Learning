{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ce350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ticklab/source/BaoTram/CO3117_Machine_Learning/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0eb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# VisoBERT\n",
    "# '''\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53ce64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01976147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./cleaned_data/train.csv')\n",
    "valid_df = pd.read_csv('./cleaned_data/valid.csv')\n",
    "test_df = pd.read_csv('./cleaned_data/test.csv')\n",
    "# Làm sạch dữ liệu\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    emoji_pattern = re.compile(\":[a-zA-Z0-9_]+:\")\n",
    "    text = emoji_pattern.sub(\"\", text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[\\s\\_]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "train_df['sentence'] = train_df['sentence'].apply(clean_text)\n",
    "valid_df['sentence'] = valid_df['sentence'].apply(clean_text)\n",
    "test_df['sentence'] = test_df['sentence'].apply(clean_text)\n",
    "# dataset = [train_df, valid_df, test_df]\n",
    "# for data in dataset:\n",
    "#     for i, text in enumerate(data['sentence'].tolist()):\n",
    "#         try:\n",
    "#             encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "#             max_id = encoding['input_ids'].max().item()\n",
    "#             if max_id >= 64001:\n",
    "#                 print(f\"Câu lỗi tại index {i}: {text}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Lỗi tại index {i}: {text}, Chi tiết: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cb7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29737 entries, 0 to 29736\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  29737 non-null  object\n",
      " 1   label     29737 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 464.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11e9fd",
   "metadata": {},
   "source": [
    "# **Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0bb2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "# Áp dụng tokenize cho từng tập dữ liệu\n",
    "train_encodings = tokenize_function(train_df['sentence'].tolist())\n",
    "valid_encodings = tokenize_function(valid_df['sentence'].tolist())\n",
    "test_encodings = tokenize_function(test_df['sentence'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac219c",
   "metadata": {},
   "source": [
    "# **Prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda89da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c16af337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_encodings, train_df['label'].tolist())\n",
    "valid_dataset = SentimentDataset(valid_encodings, valid_df['label'].tolist())\n",
    "test_dataset = SentimentDataset(test_encodings, test_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be9db0",
   "metadata": {},
   "source": [
    "# **Config train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c9fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)  # 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad919b3",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39ecf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(15004, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7239380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 1859/1859 [08:08<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2404482413284709\n",
      "Epoch 1, Valid Loss: 0.23040283209120857, Accuracy: 0.9114000604777744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 1859/1859 [08:09<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.16454656555774738\n",
      "Epoch 2, Valid Loss: 0.22777276060389484, Accuracy: 0.9184558008265296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 1859/1859 [08:10<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.0997015593318953\n",
      "Epoch 3, Valid Loss: 0.272244840523681, Accuracy: 0.9110976716056849\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Huấn luyện\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")):\n",
    "#         optimizer.zero_grad()\n",
    "#         inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "#         labels = batch['labels'].to(device)\n",
    "#         # Kiểm tra input_ids\n",
    "#         max_id = inputs['input_ids'].max().item()\n",
    "#         if max_id >= 64001:\n",
    "#             print(f\"Lỗi trong batch {i}: max input_id = {max_id}\")\n",
    "#             print(f\"input_ids: {inputs['input_ids']}\")\n",
    "#             raise ValueError(\"Tìm thấy input_id không hợp lệ\")\n",
    "#         if 'position_ids' in inputs:\n",
    "#             max_pos_id = inputs['position_ids'].max().item()\n",
    "#             if max_pos_id >= 512:  # PhoBERT max_position_embeddings thường là 512\n",
    "#                 print(f\"Lỗi trong batch {i}: max position_id = {max_pos_id}\")\n",
    "#                 print(f\"position_ids: {inputs['position_ids']}\")\n",
    "#                 raise ValueError(\"Tìm thấy position_id không hợp lệ\")\n",
    "#         outputs = model(**inputs, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         train_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader)}\")\n",
    "    \n",
    "    # Đánh giá trên tập valid\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Valid Loss: {valid_loss / len(valid_loader)}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ead04",
   "metadata": {},
   "source": [
    "# **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04a58628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9110976716056849\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2814894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ticklab/source/BaoTram/CO3117_Machine_Learning/env/lib/python3.12/site-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 256}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./modelTransformer/tokenizer_config.json',\n",
       " './modelTransformer/special_tokens_map.json',\n",
       " './modelTransformer/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./modelTransformer/\")\n",
    "tokenizer.save_pretrained(\"./modelTransformer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44dd164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"./modelTransformer/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./modelTransformer/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
